{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbial Genomics: Lab 6\n",
    "## Topic: Burrows-Wheeler Alignments and SNP Calling\n",
    "#### Tools used: BWA, SAMTools, Snippy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Lab Exercises\n",
    "### Exercise 1: Implementing a simple Burrows-Wheeler Transform\n",
    "As we discussed in class, the Burrows-Wheeler algorithm is an important concept in Bioinformatics because it gives us a way to distinctly represent, align and search very large strings in an efficient way. To start this lab, we'll look a little more closely at Burrows-Wheeler Transforms.\n",
    "\n",
    "First off, you might still be wondering about why BWT is actually important. After all, the main problem that the BWT is used to solve in Bioinformatics is searching for one block of text within a larger block. At the most basic level, we learned a few Bash commands that can search text- think of `grep`. Since sequence data is just text, can't we just use these tools to perform such searches? In theory, yes- but as with so many things in the world of Bioinformatics, the problem is a balance between memory and time.\n",
    "\n",
    "Consider the file `sample_reads.fastq` in the lab6 folder. This file has about 75,000 sequences, or about 11,000,000 reads. Say we want to search for the sequence `GATTTCCTCCTGACCAGTCG` in this file; we could do this by executing the command below. \n",
    "\n",
    "*Note: we use the `time` function to get the timing statistics of the function call, and we direct the command output to `/dev/null/` as a convention to avoid a lot of noisy output in this notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.480s\n",
      "user\t0m0.470s\n",
      "sys\t0m0.023s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "time cat lab6/sample_reads.fastq | grep \"GATTTCCTCCTGACCAGTCG\" > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So- searching a 20-length sequence across 11M reads took about 0.5 seconds. That might not seem bad; however, when you consider that this is in fact an rather small fastq file (it's not uncommon to have bacterial sequences on the order of 100x larger), that 0.5 seconds now becomes 50 seconds. That doesn't seem so bad either, but we typically aren't just querying sequences from one organism- we are querying databases with hundreds of millions of sequences. This adds up quickly- and this is a single, relatively simple query. If we begin thinking about alignment and queries involving multiple sequences, it should be clear that in order to perform bioinformatics at scale, we need a faster solution. Indexing could speed up our search problem- but at the expense of requiring *a lot* of storage space. A single human genome would require ~200GB to index; think about trying to do this for every possible species!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we've discussed why BWT is relevant, let's talk about what it means. We discussed and practiced performing a BWT manually, but how would you do so programmatically? Let's break it down into steps, and consider the word `DOGS$` for simplicity. First, we need to generate our matrix of \"rotations\"; i.e., `$DOGS`, `S$DOG`, `GS$DO`, and `OGS$D`. These form our Burrows-Wheeler Matrix:\n",
    "\n",
    "```\n",
    "DOGS$\n",
    "OGS$D\n",
    "GS$DO\n",
    "S$DOG\n",
    "$DOGS\n",
    "```\n",
    "\n",
    "From a python standpoint, we could loop N times and generate these using something along the lines of the following pseudocode:\n",
    "\n",
    "```\n",
    "def rotations(word):\n",
    "\n",
    "    rotation_list = []\n",
    "    for all i from 0 to length of word:\n",
    "    \n",
    "        rotation_list[i] = word[i to end] + word[0 to i-1]\n",
    "        \n",
    "    return rotation_list\n",
    "```\n",
    "    \n",
    "This code would return a list of all rotations of the input word. (How would you do this using a list comprehension?)\n",
    "\n",
    "Now, we need to sort our list, so that it ends up in a form like:\n",
    "\n",
    "```\n",
    "$DOGS\n",
    "DOGS$\n",
    "GS$DO\n",
    "OGS$D\n",
    "S$DOG\n",
    "```\n",
    "\n",
    "This is equivalent to sorting the output of our `rotations` function above. Once we have this sorted BWM, we can get the BWT by taking the last letter of each row (i.e., the last letter of each element in the sorted list in Python).\n",
    "\n",
    "Use the cell below to implement a function that takes in any arbitrary word, and returns its BWT. You can implement the internals any way you'd like, as long as the valid transformation is returned. Demonstrate that your function works on a word of your choosing after you define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NPKT$ILOA'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "def bwt(word):\n",
    "    \n",
    "    rotation_list = sorted([word[i:] + word[0:i] for i in range(len(word))])\n",
    "    word_bwt = ''.join([x[-1] for x in rotation_list])\n",
    "    return word_bwt\n",
    "\n",
    "bwt(\"LOPATKIN$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Using the `bwa` package\n",
    "Above, we implemented a very simple Burrows Wheeler Transform. In reality, our Computer Science friends have been hard at work over the past 40 years making much, much more sophisticated versions of this code; there are doctoral dissertations on this topic alone. Fortunately for us, we get to reap the benefits of this hard work without getting a PhD!\n",
    "\n",
    "There are quite a few packages that use BWT (or a related variant), but we'll focus on the `bwa`, or Burrows-Wheeler Alignment, package. You can see the basics of the tool, as always, by typing `bwa` in the command line (or the below cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: bwa: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'bwa\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-67837c01c1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bwa\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/alopatki/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'bwa\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bwa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note from this output that `bwa` has quite a few subcommands; the output also gives a brief description of each. The main ones of note for us are `index`, `mem`, `aln`, and `sampe`. **Do your own investigation into each of these and answer the questions below:**\n",
    "\n",
    "1. What does each of the 4 subcommands listed above do?\n",
    "2. If you were given a .fasta file and two .fastq files as inputs, and wanted to output a .sam file, what command(s) would you run?\n",
    "3. Read the documentation at https://github.com/lh3/bwa. Is there more than one way to answer the above question? If so, what is the alternative to the answer you gave? Is there any reason to use one over another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Variants\n",
    "Above, we learned about creating alignments with BWA; we've performed a similar workflow with Samtools in Lab 4. BWA-MEM is a much easier and faster way to perform alignments, and more importantly, brings us to our next topic: what do we do with those SAM files we generated?\n",
    "\n",
    "One common question bioinformaticians usually want to answer when dealing with a sequence is, \"how is this sequence different from a known reference\"? Alignment of two sequences gives us a \"birds-eye\" view of the differences between them, but we can look for more granular differences in the form of single nucleotide polymorphisms (SNPs), also known as \"variants\". These are common mutations where a single nucleotide has changed, and can be quantified. The act of finding these variants between two genomes is known as \"SNP Calling\" or \"Variant Calling\".\n",
    "\n",
    "To perform SNP calling, we need two things: a reference, or known, genome, and a \"new\" genome that we want to compare it to. Different tools have different requirements on the formats of these inputs, but there are 4 main input filetypes you will encounter:\n",
    "* `.fasta`, for the reference genome: this is our well-known friend- nothing new about it.\n",
    "* `.gbk`, for the reference genome: a genbank file is sometimes used as the reference input; this can be retrived from any sequence on NCBI.\n",
    "* `.fastq`, for the genome to be called: some tools will accept raw fastq reads; this is the easiest option.\n",
    "* `.BAM`, for genome to be called: this is a binary-compressed version of the `.SAM` format, which contains aligned, mapped sequences.\n",
    "\n",
    "The output files will generally be one of two filetypes:\n",
    "* VCF files are uncompressed files that contain variants found in a sequence compared to a reference. \n",
    "* BCF files are a binary compressed version of VCF files.\n",
    "\n",
    "A VCF file will look something like this:\n",
    "```\n",
    "##fileformat=VCFv4.3\n",
    "##fileDate=20090805\n",
    "##source=myImputationProgramV3.1\n",
    "##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta\n",
    "< ... more lines go here ... >\n",
    "#CHROM POS      ID         REF   ALT    QUAL  FILTER   INFO                             FORMAT       NA00001         NA00002          NA00003\n",
    "20     14370    rs6054257  G     A      29    PASS    NS=3;DP=14;AF=0.5;DB;H2           GT:GQ:DP:HQ  0|0:48:1:51,51  1|0:48:8:51,51   1/1:43:5:.,.\n",
    "20     17330    .          T     A      3     q10     NS=3;DP=11;AF=0.017               GT:GQ:DP:HQ  0|0:49:3:58,50  0|1:3:5:65,3     0/0:41:3\n",
    "20     1110696  rs6040355  A     G,T    67    PASS    NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ  1|2:21:6:23,27  2|1:2:0:18,2     2/2:35:4\n",
    "20     1230237  .          T     .      47    PASS    NS=3;DP=13;AA=T                   GT:GQ:DP:HQ  0|0:54:7:56,60  0|0:48:4:51,51   0/0:61:2\n",
    "20     1234567  microsat1  GTC   G,GTCT 50    PASS    NS=3;DP=9;AA=G                    GT:GQ:DP     0/1:35:4        0/2:17:2         1/1:40:3\n",
    "```\n",
    "\n",
    "Here, we have a bunch of reference information preceded with `##` at the top, followed by tab-separated variant information. Each line in the \"main\" table of the file represents one variant.\n",
    "\n",
    "To try out some variant calling, we'll first use BWA to generate our aligned `.sam` files, convert to `.bam` with SAMTools, and then call variants using BCFTools, which is a sub-tool of SAMTools. The pipeline will look like this:\n",
    "1. Input paired-end fastq and reference fasta files to `bwa-mem`; output a SAM file\n",
    "2. Input the SAM file to `samtools view -bS` and output a BAM file\n",
    "3. Sort the BAM file using `samtools sort` to output a sorted BAM file\n",
    "4. Generate a BCF by using the `bcftools mpileup` and `bcftools call` commands\n",
    "\n",
    "**Based on this information, complete the below exercises:**\n",
    "1. Familiarize yourself with the SAMTools SNP-calling pipeline by reading [this guide](http://samtools.sourceforge.net/mpileup.shtml) and performing your own research on Google, Biostars, etc. Once you feel confident that you understand the steps, write a pipeline that uses reads_1.fastq, reads_2.fastq, and reference.fasta from the lab6 folder to generate a BCF file of variants between the fastq files and the reference fasta.\n",
    "2. Investigate the BCF file you just generated by using the `bcftools view` command to convert your BCF file to a VCF file. Open this file in your text editor of choice. How many variants did you find?\n",
    "3. Do some basic analytics of your VCF file. You can do this either by using Excel (copy all of the lines after `##` ends), or using Python, MATLAB, or your programming tool of choice. What are the most common variants you called (hint: these are the values in the `ALT` column)? \n",
    "4. Does the VCF tell us what each of these mutations actually does? If not, what other information would we need to make some judgement about the impact of each variant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: SNP Calling with Snippy\n",
    "SAMTools is part of the \"classic\" variant-calling pipeline; it was one of the very early tools developed to aid bioinformaticians in understanding their data. However, as you likely saw in the previous exercise, it is not always the most user-friendly tool. Another tool we can use to build a variant-calling pipeline is `snippy`, from the (rather prolific) Australian Bioinformatician Torsten Seemann. The github page can be found [here](https://github.com/tseemann/snippy); take some time to read through it. It is already installed in this environment, so you can view the help as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "snippy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snippy is a very useful tool for several reasons:\n",
    "* It can take as inputs our fastq files directly; there's no need to align them first\n",
    "* It can take a Genbank file as an input, which can be directly downloaded from NCBI (i.e., using Biopython)\n",
    "* It outputs a host of very useful files, most of which are very user-friendly (unlike raw VCFs)\n",
    "\n",
    "We'll be using this tool extensively in the rest of the course, but for now, complete the exercise below using `snippy`:\n",
    "1. Use Biopython Entrez to download a reference GBK file for E Coli SubSp. MG1655 (it may be useful to first do this via the [web UI](https://www.ncbi.nlm.nih.gov/nuccore/U00096.2), but for the exercise, it should be done in biopython)\n",
    "2. Run `snippy` on the reads read_1.fastq and read_2.fastq in the lab6 folder; output should be placed in lab6/results/\n",
    "3. Look through the output generated by `snippy`; open the .html file that was generated. Summarize and discuss your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about several different technologies in this lab; now, we'll put a few of them to use. Your homework this week will be to explore mutations in a resistant strain of *E. Coli* isolated from patients at a New York City hospital. It will be your job to write code that accomplishes the following:\n",
    "1. Use BLAST to find the most closely-related strain of *E. Coli* in the NCBI database\n",
    "2. Download the reference genome for that strain\n",
    "3. QC and trim the input fastq files as you deem necessary\n",
    "4. Align your fastq reads to the reference you downloaded, and call variants using whichever tool you prefer\n",
    "5. Analyze and summarize your findings by performing a literature search, and referencing at least one paper that might describe the impacts of the mutations you found\n",
    "\n",
    "Each step above is worth 20 points; you can write each one in a separate script, use this notebook, or write several external scripts, but you must provide a write-up of your findings in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework Question 5 Writeup Goes Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
